{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Intervals\n",
    "\n",
    "In the previous lecture we have measured the accuracy of our **point forecast**.  \n",
    "\n",
    "We should always recognise that when we forecast the future there is a degree of uncertainty in our point forecast. If we focus only on point forecasts then we ignore this uncertainty.  \n",
    "\n",
    "The point forecast we used in the baseline analysis was actually the mean of a **forecast distribution**.  Taking a statistical perspective to forecasting allows us to make inference about our forecast uncertainty via **prediction intervals**.\n",
    "\n",
    "**In the lecture you will learn**\n",
    "\n",
    "* The difference between a confidence interval and a prediction interval\n",
    "* How to generate a prediction interval for baseline forecast methods.\n",
    "* How to evaluate the accuracy (called coverage) of a prediction interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.style as style\n",
    "style.use('ggplot')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from forecast.baseline import Naive1, Drift, SNaive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_as_series(data, preds):\n",
    "    '''\n",
    "    Helper function for plotting predictions.\n",
    "    Converts a numpy array of predictions to a \n",
    "    pandas.DataFrame with datetimeindex\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    preds - numpy.array, vector of predictions\n",
    "    start - start date of the time series\n",
    "    freq - the frequency of the time series e.g 'MS' or 'D'\n",
    "    '''\n",
    "    start = pd.date_range(start=data.index.max(), periods=2, freq=data.index.freq).max()\n",
    "    idx = pd.date_range(start=start, periods=len(preds), freq=data.index.freq)\n",
    "    return pd.DataFrame(preds, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_intervals(train, preds, intervals, \n",
    "                              test=None):\n",
    "    '''\n",
    "    Helper function to plot training data, point preds\n",
    "    and 2 sets of prediction intevals\n",
    "    \n",
    "    assume 2 sets of PIs are provided!\n",
    "    '''\n",
    "    ax = train.plot(figsize=(12,4))\n",
    "\n",
    "    mean = preds_as_series(train, preds)\n",
    "    intervals_80 = preds_as_series(train, intervals[0])\n",
    "    intervals_90 = preds_as_series(train, intervals[1])\n",
    "\n",
    "    mean.plot(ax=ax, label='point forecast')\n",
    "\n",
    "    ax.fill_between(intervals_80.index, mean[0], intervals_80[1], \n",
    "                    alpha=0.2,\n",
    "                    label='80% PI', color='yellow');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,mean[0], intervals_80[0], \n",
    "                    alpha=0.2,\n",
    "                    label='80% PI', color='yellow');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,intervals_80[1], intervals_90[1], \n",
    "                    alpha=0.2,\n",
    "                    label='90% PI', color='purple');\n",
    "\n",
    "    ax.fill_between(intervals_80.index,intervals_80[0], intervals_90[0], \n",
    "                    alpha=0.2,\n",
    "                    label='90% PI', color='purple');\n",
    "    \n",
    "    if test is None:\n",
    "        ax.legend(['train', 'point forecast', '80%PI', '_ignore','_ignore', '90%PI'], loc=2)\n",
    "    else:\n",
    "        test.plot(ax=ax, color='black')\n",
    "        ax.legend(['train', 'point forecast', 'Test', '80%PI', '_ignore','_ignore', '90%PI'], loc=2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, train-test split the data for this lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_month = pd.read_csv('data/ed_mth_ts.csv', index_col='date', parse_dates=True)\n",
    "ed_month.index.freq='MS'\n",
    "arrival_rate = ed_month['arrivals'] / ed_month.index.days_in_month\n",
    "\n",
    "#train test split\n",
    "train_length = arrival_rate.shape[0] - 12\n",
    "train, test = arrival_rate.iloc[:train_length], arrival_rate.iloc[train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals Versus Prediction Intervals\n",
    "\n",
    "Many people are familar with the concept of Confidence Intervals.  However, for forecasting we must use a related but slightly different concept called the prediction interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "Imagine you want to estimate the mean height of adults in the UK. You are standing in a room and adults enter one-by-one and you measure and record their heights. After 30 people have visited you calculate their mean height.  This is the sample mean: an estimate of the true population parameter based on a random sample of observations.  As your sample is finite, your estimate is subject to some uncertainty. \n",
    "\n",
    "How do you quantify that uncertainty?\n",
    "\n",
    "This is where confidence interval's (CIs) are used.  If you repeated the experiment 100 times and each time calculated a 95% CI then you would expect 95 of those intervals to contain the true mean height of adults and 5 to not contain it.  A CI therefore provides a statistical estimate of the distribution of the true mean height of the adults if you repeated the experiment many times.|\n",
    "\n",
    "### Prediction Intervals\n",
    "\n",
    "Now imagine that you continue the experiment with a slight twist. Your job is to now predict the height of person 31 i.e. the **next person that arrives**.  \n",
    "\n",
    "To quantify the uncertainty in a individual prediction you must provide an interval with a specified probability.  A Prediction Interval (PI) must account for the uncertainty in estimating the population mean height and the random variation you see with each person.  This means that a 95% PI is much wider than a 95% CI.\n",
    "\n",
    "The key point is that CIs focus on estimating population parameters from observed data (e.g. mean height) whereas PIs focus on the uncertainty of a prediction of a unobserved future value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty and forecast horizons\n",
    "\n",
    "A general rule of thumb is that our forecast accuracy decreases the further into the future we predict.  The more uncertainty in a forecast the wider the prediction interval.\n",
    "\n",
    "To put it another way the further ahead you forecast the wider a prediction interval.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf1 = Naive1()\n",
    "nf1.fit(train)\n",
    "preds, intervals = nf1.predict(horizon=12, return_predict_int=True, alphas=[0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_intervals(train, preds, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_intervals(train, preds, intervals, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a predicton interval\n",
    "\n",
    "In practice, producing a prediction interval that offers the correct level of coverage is tricky. If the model is a poor fit then it will produce PIs that are too wide.  While more complex methods tend to be overconfident and produce intervals that are too narrow.  \n",
    "\n",
    "In this example we will use the MAE of the point predictions to choose between Naive1 and SNaive.  We will then use the best method to produce PIs and measure their empirical coverage of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('data/Alcohol_Sales.csv', index_col='DATE', parse_dates=True)\n",
    "sales.index.freq = 'MS'\n",
    "sales_rate = sales['sales'] / sales.index.days_in_month\n",
    "\n",
    "HORIZON = 12\n",
    "train = sales_rate.iloc[:len(sales) - HORIZON]\n",
    "test = sales_rate.iloc[len(sales) - HORIZON:]\n",
    "\n",
    "#log transform the data\n",
    "train = np.log(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models and generate point forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snf = SNaive(period=12)\n",
    "snf.fit(train)\n",
    "snf_preds = snf.predict(horizon=HORIZON)\n",
    "\n",
    "nf1 = Naive1()\n",
    "nf1.fit(train)\n",
    "nf1_preds = nf1.predict(horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcluate out of sample MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back transform the point forecasts\n",
    "snf_preds = np.exp(snf_preds)\n",
    "nf1_preds = np.exp(nf1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE SNaive\n",
    "mean_absolute_error(y_true=test, y_pred=snf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE Naive1\n",
    "mean_absolute_error(y_true=test, y_pred=nf1_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusion!  SNaive has the lower MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and Plot Prediction Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snf_preds, snf_intervals = snf.predict(horizon=HORIZON, \n",
    "                                       return_predict_int=True, \n",
    "                                       alphas=[0.2, 0.05])\n",
    "\n",
    "#back transform the point forecasts\n",
    "snf_preds = np.exp(snf_preds)\n",
    "snf_intervals = np.exp(snf_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_intervals(np.exp(train[-12:]), snf_preds, snf_intervals, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast.metrics import coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% Predictions intervals\n",
    "coverage(y_true=test, pred_intervals=snf_intervals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#95% Predictions intervals\n",
    "coverage(y_true=test, pred_intervals=snf_intervals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
