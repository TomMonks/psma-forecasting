{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Smoothing Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aims of Exponential Smoothing Procedures\n",
    "* In the naive forecasting method we assumed that the most recent observation was the most important.\n",
    "* In the average method, we used all observations, but gave them all equal weight (they were all equally important).\n",
    "* Exponential smoothing falls between these two extremes.\n",
    " * ES forecasts are weighted averages of past observations.\n",
    " * More recent observations carry more weight than older ones;\n",
    " * Or to put it another way: the weights decrease exponentially as the observations get older.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Exponential Smoothing Procedure\n",
    "* **Simple Exponential Smoothing (SES)**\n",
    " * No trend or seasonality\n",
    "* **Holt's Linear Method**\n",
    " * Extends (SES) to include a linear trend\n",
    "* **Holt-Winters Exponential Smoothing (HW)**\n",
    " * The most complex procedure that handles both trend and seasonality\n",
    " \n",
    "Both Holt's linear method and HW can include a damped trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Exponential Smoothing (SES)\n",
    "SES consists of two equations the forecast equation (1.1) and the smoothing equation (1.2):\n",
    "<div class=\"alert alert-block alert-warning\"><b>SES</b>\n",
    "\n",
    "$F_{t+h} = l_t \\tag{1.1}$\n",
    "\n",
    "$l_{t} = \\alpha y_t + (1 - \\alpha) l_{t-1} \\tag{1.2} $\n",
    "</div>\n",
    "\n",
    "**where** \n",
    "* $\\alpha$ = a smoothing parameter between 0 and 1.\n",
    "* $l_t$ = the current level at time t.\n",
    "* $y_t$ = The ground truth / real world observation at time t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't worked with equations for a while this might look complicated.   The reality is that it is a very simple method. To output a forecast involves plugging a few numbers.\n",
    "\n",
    "Equation (1.2) is called the smoothing or level equation.  In words level ($l_{t}$) is based on weighting the most recent observation ($y_t$) by a smoothing constant called $\\alpha$ and weighting the previous level by $(1-\\alpha)$.  \n",
    "\n",
    "**Smoothing Example 1**\n",
    "\n",
    "* $y_t = 150$\n",
    "* $l_{t-1} = 120$\n",
    "* $alpha = 0.2$\n",
    "* $l_{t} = \\alpha y_t + (1 - \\alpha) l_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_level(obs, level, alpha):\n",
    "    '''Returns a exponentially smoothed level assuming \n",
    "    no trend or seasonality'''\n",
    "    return (alpha * obs) + ((1 - alpha)*level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_obs = 150\n",
    "last_level = 120\n",
    "alpha = 0.2\n",
    "\n",
    "#call the function that implements the smoothing eq.\n",
    "smooth_level(current_obs, last_level, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing Example 2**\n",
    "\n",
    "* $y_t = 150$\n",
    "* $l_{t-1} = 120$\n",
    "* $alpha = 0.8$\n",
    "\n",
    "**Question: What happens when alpha is set to 0.0 or 1.0?**\n",
    "\n",
    "**What does this tell you about the role of alpha?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_obs = 150  #y_t\n",
    "last_level = 120   #l_t-1\n",
    "alpha = 0.8  \n",
    "\n",
    "#call the function that implements the smoothing eq.\n",
    "smooth_level(current_obs, last_level, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation (1.1)** is called the *forecast equation*.  In words is means that the forecast h steps ahead is equal to the current level.  In otherwords **it is a flat forecast**.  It just carries the last value produced the smoothing equation forward.  We will see a visual example of that shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SES Forecast Example**\n",
    "\n",
    "Given the following inputs, create a 6 step ahead forecast.\n",
    "\n",
    "* $y_t = 150$\n",
    "* $l_{t-1} = 120$\n",
    "* $alpha = 0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_forecast(level, horizon):\n",
    "    '''Returns a vector of length horizon with all values \n",
    "    set to level'''\n",
    "    return np.full(shape=horizon, fill_value=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_obs = 150\n",
    "last_level = 120\n",
    "ALPHA = 0.2\n",
    "HORIZON = 6\n",
    "\n",
    "#call the function that implements the smoothing eq.\n",
    "new_level = smooth_level(current_obs, last_level, ALPHA)\n",
    "flat_forecast(new_level, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/statsmodels-logo-v2-horizontal.svg\" style=\"width: 200px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The good news is that you do not need to implement SES or the other more complex versions of Exponential Smoothing.**\n",
    "\n",
    "[statsmodels](https://www.statsmodels.org/stable/index.html) is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two statsmodels libraries that you can use for SES.\n",
    "\n",
    "```python\n",
    "statsmodels.tsa.holtwinters.SimpleExpSmoothing\n",
    "```\n",
    "The `SimpleExpSmoothing` [class](https://www.statsmodels.org/stable/generated/statsmodels.tsa.holtwinters.SimpleExpSmoothing.html?highlight=simpleexpsmoothing#statsmodels.tsa.holtwinters.SimpleExpSmoothing) implements the SES equations described above.  It is fast easy to use and provides an optimisation procedure to automatically select the best $\\alpha$ value.\n",
    "\n",
    "```python\n",
    "statsmodels.tsa.statespace.exponential_smoothing.ExponentialSmoothing\n",
    "```\n",
    "\n",
    "The `ExponentialSmoothing` class implements SES as a **statistical model**.  The theory of this is beyond the scope of this tutorial, but the fundermental idea is that the class provides a statistical model that is equivalent to the mathematical model outlined above.  The advantage of the statistical model is that point forecasts can be enhanced with a **prediction interval**.  Where possible, it is recommended that point forecasts are always accompanied by a prediction interval.  For this reason it is recommended that the [statespace implementation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.exponential_smoothing.ExponentialSmoothing.html?highlight=statespace%20exponential) is used over and above `SimpleExpSmoothing`.\n",
    "\n",
    "For more information on the statespace formulation I recommend reading the relevant [chapter](https://otexts.com/fpp2/ets.html) Prof Rob Hyndman's free and open book on forecasting.\n",
    "\n",
    "**SES Example: Nile flow data 1871 to 1930**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nile = pd.read_csv('data/nile.csv', index_col='year', parse_dates=True)\n",
    "nile.index.freq = \"AS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nile['flow'].plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.exponential_smoothing import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the next dacade of flow.\n",
    "HORIZON = 10\n",
    "\n",
    "#for SES pass in the endog argument as your data\n",
    "model = ExponentialSmoothing(endog=nile['flow'])\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.get_forecast(steps=HORIZON)\n",
    "\n",
    "#the summary_frame() method returns a pandas data frame.\n",
    "#here alpha refers to alpha for a prediction interval 0.2 = 80% pred interval.\n",
    "#make sure you don't confuse this alpha with the SES smoothing parameter!\n",
    "preds.summary_frame(alpha=0.2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the fitted values and prediction\n",
    "ax = nile['flow'].plot(figsize=(12,4))\n",
    "forecast_80 = preds.summary_frame(alpha=0.2)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "forecast_90 = preds.summary_frame(alpha=0.1)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "\n",
    "\n",
    "ax.fill_between(forecast_90.index,forecast_90['mean_ci_lower'], forecast_90['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='90% PI');\n",
    "\n",
    "ax.fill_between(forecast_80.index,forecast_80['mean_ci_lower'], forecast_80['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='80% PI');\n",
    "\n",
    "forecast_80['mean'].plot(ax=ax, label='forecast', color='red');\n",
    "\n",
    "results.fittedvalues.plot(ax=ax, label='fitted', color='green', linestyle='--')\n",
    "\n",
    "ax.legend(loc=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets have a look at the fitted model\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt's Method for Linear Trend\n",
    "\n",
    "Holt's linear method adds a second smoothing parameter $\\beta$ and a third equation representing the trend.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Holt's Linear Method</b>\n",
    "\n",
    "$F_{t+h} = l_t + hb_t \\tag{2.1}$\n",
    "\n",
    "\\begin{equation}\n",
    "    l_t = \\alpha Y_t + (1 - \\alpha) (l_{t-1} + b_{t-1}) \\tag{2.2}\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "    b_t = \\beta (l_t - l_{t-1}) + (1 - \\beta)b_{t-1} \\tag{2.3}\n",
    "\\end{equation}\n",
    "</div>\n",
    "\n",
    "\n",
    "**Example: US Gross Domestic Product 1920 to 2019.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/GDPCA.csv', index_col='DATE', parse_dates=True)\n",
    "train.index.freq = 'AS'\n",
    "train.plot(figsize=(12,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast 30 years ahead.\n",
    "HORIZON = 30\n",
    "\n",
    "#pass in the trend parameter as true\n",
    "model = ExponentialSmoothing(endog=train, trend=True)\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.get_forecast(steps=HORIZON)\n",
    "\n",
    "#here alpha refers to alpha for a prediction interval \n",
    "#(not to be confused with the smoothing parameter!)\n",
    "preds.summary_frame(alpha=0.2).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train.plot(figsize=(12,4))\n",
    "\n",
    "forecast_80 = preds.summary_frame(alpha=0.2)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "forecast_90 = preds.summary_frame(alpha=0.1)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "\n",
    "\n",
    "ax.fill_between(forecast_90.index,forecast_90['mean_ci_lower'], forecast_90['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='90% PI');\n",
    "\n",
    "ax.fill_between(forecast_80.index,forecast_80['mean_ci_lower'], forecast_80['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='80% PI');\n",
    "\n",
    "forecast_90['mean'].plot(ax=ax, color='red')\n",
    "results.fittedvalues.plot(ax=ax, color='green', linestyle='--')\n",
    "ax.legend(['train', 'point forecast', 'fitted','90%PI', '80% PI']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing a damped trend.\n",
    "\n",
    "It is often beneficial to introduce a damped trend into long term forecasting.  The following code illustrates the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast 30 years ahead.\n",
    "HORIZON = 30\n",
    "\n",
    "#note the damped_trend parameter\n",
    "model = ExponentialSmoothing(endog=train, trend=True, damped_trend=True)\n",
    "results = model.fit()\n",
    "preds = results.get_forecast(steps=HORIZON)\n",
    "\n",
    "ax = train.plot(figsize=(12,4))\n",
    "forecast_80 = preds.summary_frame(alpha=0.2)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "forecast_90 = preds.summary_frame(alpha=0.1)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "ax.fill_between(forecast_90.index,forecast_90['mean_ci_lower'], forecast_90['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='90% PI');\n",
    "ax.fill_between(forecast_80.index,forecast_80['mean_ci_lower'], forecast_80['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='80% PI');\n",
    "forecast_90['mean'].plot(ax=ax, color='red')\n",
    "results.fittedvalues.plot(ax=ax, color='green', linestyle='--')\n",
    "ax.legend(['train', 'point forecast', 'fitted','90%PI', '80% PI']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters Exponential Smoothing\n",
    "\n",
    "* Holt-Winters (HW) Exponential Smoothing procedures handle **trend and seasonality**. \n",
    "* There are two versions of HW that that handle additive and multiplicative seasonality.\n",
    "* In both cases a seasonality equation and a seasonal smoothing constant $\\gamma$ are added.\n",
    "* The level $l_t$ is seasonally adjusted\n",
    " * additive model: the seasonal component is an absolute value subtracted from the level\n",
    " * multiplicative model: the seasonal component is a percentage.  The level is divided by it.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Method\n",
    "\n",
    "The additive approach is used when the variance in the data is roughly constant.  \n",
    "\n",
    "<font size=\"4\">\n",
    "<div class=\"alert alert-block alert-warning\"><b>HW Additive</b>\n",
    "\n",
    "$F_{t+h} = l_t + hb_t + s_{t+h-m(k+1)}\\tag{3.1}$\n",
    "\n",
    "\\begin{equation}\n",
    "    l_t = \\alpha (y_t - s_{t-m}) + (1 - \\alpha) (l_{t-1} + b_{t-1}) \\tag{3.2}\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "    b_t = \\beta (l_t - l_{t-1}) + (1 - \\beta)b_{t-1} \\tag{3.3}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    s_t = \\gamma (y_t - l_t - s_{t-m}) + (1 - \\gamma) s_{t-m} \\tag{3.4}\n",
    "\\end{equation}\n",
    "</div>\n",
    "    </font>\n",
    "\n",
    "**Additive example.  Australian quarterly beer production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.datasets import load_ausbeer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausbeer = load_ausbeer(as_series=True)\n",
    "#index is 1956:Q1 to 2008:Q3\n",
    "ausbeer.index = pd.date_range(start='1956Q1', periods=212, freq='Q')\n",
    "ausbeer.plot(figsize=(12,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the next 10 years\n",
    "HORIZON = 40\n",
    "\n",
    "#for SES pass in the endog argument as your data\n",
    "model = ExponentialSmoothing(endog=ausbeer, seasonal=4)\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.get_forecast(steps=HORIZON)\n",
    "preds.summary_frame(alpha=0.2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ausbeer.plot(figsize=(12,4))\n",
    "forecast_80 = preds.summary_frame(alpha=0.2)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "forecast_90 = preds.summary_frame(alpha=0.1)[['mean', 'mean_ci_lower', 'mean_ci_upper']]\n",
    "ax.fill_between(forecast_90.index,forecast_90['mean_ci_lower'], forecast_90['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='90% PI');\n",
    "ax.fill_between(forecast_80.index,forecast_80['mean_ci_lower'], forecast_80['mean_ci_upper'], \n",
    "                alpha=0.5,\n",
    "                label='80% PI');\n",
    "forecast_90['mean'].plot(ax=ax, color='red')\n",
    "results.fittedvalues.plot(ax=ax, color='green', linestyle='--')\n",
    "ax.legend(['train', 'point forecast', 'fitted','90%PI', '80% PI'], bbox_to_anchor=(1.05, 1), loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Method\n",
    "\n",
    "The multiplicative approach is used when variance in the data increases/decreases over time.\n",
    "\n",
    "<font size=\"4\">\n",
    "<div class=\"alert alert-block alert-warning\"><b>HW Mutliplicative</b>\n",
    "$F_{t+h} = (l_t + hb_t)s_{t+h-m(k+1)}\\tag{3.5}$\n",
    "\n",
    "\\begin{equation}\n",
    "    l_t = \\alpha \\frac{y_t}{s_{t-m}} + (1 - \\alpha) (l_{t-1} + b_{t-1}) \\tag{3.6}\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "    b_t = \\beta (l_t - l_{t-1}) + (1 - \\beta)b_{t-1} \\tag{3.7}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    s_t = \\gamma \\frac{y_t}{l_t - s_{t-m}} + (1 - \\gamma) s_{t-m} \\tag{3.8}\n",
    "\\end{equation}\n",
    "</div>\n",
    "    </font>\n",
    "\n",
    "\n",
    "**Multiplicative Seasonality Example: Alcohol Sales $m**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example sales of beer wine IN $m\n",
    "train = pd.read_csv('data/Alcohol_Sales.csv', index_col='DATE', parse_dates=True)\n",
    "train.index.freq = 'MS'\n",
    "train.plot(figsize=(12,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast 120 months ahead.\n",
    "HORIZON = 120\n",
    "\n",
    "#trend='add' means model with a linear trend. seasonal='mul' means to use multiplicative seasoniality.\n",
    "model = ExponentialSmoothing(endog=train, trend='add', seasonal='mul', \n",
    "                             seasonal_periods=12)\n",
    "results = model.fit()\n",
    "preds = results.forecast(steps=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(start='2020-01-01', periods=HORIZON, freq='MS')\n",
    "ax = train.plot(figsize=(12,4))\n",
    "results.fittedvalues.plot(ax=ax, color='green', linestyle='--')\n",
    "pd.Series(preds, index=idx).plot(ax=ax);\n",
    "ax.legend(['train', 'point forecast', 'fitted']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Question: what happens if we assume additive seasonality or multiplicative trend?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look at the fitted model\n",
    "results.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
